{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5877594",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "998c35ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from utils import counter_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a3c64c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input_list(path, mode='r'):\n",
    "    with open(path, mode) as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # Skip the header\n",
    "        return [row[0] for row in reader]\n",
    "\n",
    "\n",
    "def read_input_counter(path, mode='r'):\n",
    "    with open(path, mode) as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # Skip the header\n",
    "        return Counter({row[0]: int(row[1]) for row in reader})\n",
    "    \n",
    "\n",
    "neg_list = read_input_list(\"neg_list.csv\")\n",
    "pos_list = read_input_list(\"pos_list.csv\")\n",
    "neg_counter = read_input_counter(\"neg_counter.csv\")\n",
    "pos_counter = read_input_counter(\"pos_counter.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50936ae",
   "metadata": {},
   "source": [
    "## 2. Investigate the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df993f02",
   "metadata": {},
   "source": [
    "**Task 1**  \n",
    "- Let’s look at the data given to us. \n",
    "- Print `pos_list[0]`. \n",
    "- Would you classify this review as positive or negative?\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 2**  \n",
    "- Take a look at the first review in `neg_list` as well. \n",
    "- Does that one look negative?\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 3**  \n",
    "- We’ve also created a Counter object for all of the positive reviews and one for all of the negative reviews. \n",
    "- These counters are like Python dictionaries — you could find the number of times the word “baby” was used in the positive reviews by printing `pos_counter['baby']`.\n",
    "- Print the number of times the word “crib” was used in the positive and negative reviews. In which set was it used more often?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d50b5e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect for new parents. We were able to keep track of baby's feeding, sleep and diaper change schedule for the first two and a half months of her life. Made life easier when the doctor would ask questions about habits because we had it all right there!\n",
      "I wanted to love this, but it was pretty expensive for only a few months worth of calendar pages.  I ended up buying a regular weekly planner - 55% OFF! - The Planner - that is 8 1/2 x 11 and has all seven days on the right page and the left page has room to write a To Do List and Goals.  I found this to be more helpful because I could mark each day's eating and sleeping blocks, then also see them side by side - I could see her patterns more easily with a weekly view.  This planner was cute, just not what I wanted.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Task 1\n",
    "print(pos_list[0])  # positive\n",
    "\n",
    "# Task 2\n",
    "print(neg_list[0])  # negative\n",
    "\n",
    "# Task 3\n",
    "print(pos_counter[\"crib\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b459e7",
   "metadata": {},
   "source": [
    "## 3. Bayes Theorem I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed53b64",
   "metadata": {},
   "source": [
    "**Task 1**  \n",
    "- Find the total number of positive reviews by finding the length of `pos_list`.\n",
    "- Do the same for `neg_list`.\n",
    "- Add those two numbers together and save the sum in a variable called `total_reviews`.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 2**  \n",
    "- Create variables named `percent_pos` and `percent_neg`. \n",
    "- `percent_pos` should be the number of positive reviews divided by `total_reviews`. \n",
    "- Do the same for `percent_neg`.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 3**  \n",
    "- Print `percent_pos` and `percent_neg`. \n",
    "- They should add up to 1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f328b483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Task 1\n",
    "total_reviews = len(neg_list) + len(pos_list)\n",
    "print(total_reviews)  \n",
    "\n",
    "# Task 2 / 3\n",
    "percent_pos = len(pos_list) / total_reviews \n",
    "print(percent_pos)\n",
    "percent_neg = len(neg_list) / total_reviews \n",
    "print(percent_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c33db7a",
   "metadata": {},
   "source": [
    "## 4. Bayes Theorem II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac9d8be",
   "metadata": {},
   "source": [
    "**Task 1**  \n",
    "- Let’s first find the total number of words in all positive reviews and store that number in a variable named `total_pos`.\n",
    "- To do this, we can use the built-in Python `sum()` function. \n",
    "- `sum()` takes a list as a parameter. \n",
    "- The list that you want to sum is the `values` of the dictionary `pos_counter`, which you can get by using `pos_counter.values()`.\n",
    "- Do the same for `total_neg`.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 2**  \n",
    "- Create two variables named `pos_probability` and `neg_probability`. \n",
    "- Each of these variables should start at `1`. \n",
    "- These are the variables we are going to use to keep track of the probabilities.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 3**  \n",
    "- Create a list of the words in review and store it in a variable named `review_words`. \n",
    "- You can do this by using Python’s `.split()` function.\n",
    "- For example if the string test contained \"Hello there\", then `test.split()` would return `[\"Hello\", \"there\"]`.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 4**  \n",
    "- Loop through every word in `review_words`. \n",
    "- Find the number of times word appears in `pos_counter` and `neg_counter`. \n",
    "- Store those values in variables named `word_in_pos` and `word_in_neg`.\n",
    "- In the next steps, we’ll use this variable inside the for loop to do a series of multiplications.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 5**  \n",
    "- Inside the for loop, set `pos_probability` to be `pos_probability` multiplied by `word_in_pos / total_pos`.\n",
    "- This step is finding each term to be multiplied together. \n",
    "- For example, when `word` is `\"crib\"`, you’re calculating the following:\n",
    "$$ P(\\text{\"crib\"} | \\text{positive}) = \\frac{\\text{\\# of \"crib\" in positive}}{\\text{\\# of words in positive}} $$\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 6**  \n",
    "- Do the same multiplication for `neg_probability`.\n",
    "- Outside the for loop, print both `pos_probability` and `neg_probability`. \n",
    "- Those values are P(“This crib was amazing”|positive) and `P(“This crib was amazing”|negative)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48f9539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"This crib was amazing\"\n",
    "\n",
    "percent_pos = 0.5\n",
    "percent_neg = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68f48490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 1\n",
    "total_pos = sum(pos_counter.values())\n",
    "total_neg = sum(neg_counter.values())\n",
    "\n",
    "# Task 2\n",
    "pos_probability = 1\n",
    "neg_probability = 1\n",
    "\n",
    "# Task 3\n",
    "review_words = review.split()\n",
    "\n",
    "# Task 4 / 5 / 6\n",
    "for word in review_words:\n",
    "    word_in_pos = pos_counter[word]\n",
    "    word_in_neg = neg_counter[word]\n",
    "    \n",
    "    pos_probability *= word_in_pos / total_pos\n",
    "    neg_probability *= word_in_neg / total_neg\n",
    "\n",
    "# Task 6\n",
    "pos_probability, neg_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c4df04",
   "metadata": {},
   "source": [
    "## 5. Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438374aa",
   "metadata": {},
   "source": [
    "**Task 1**  \n",
    "- Let’s demonstrate how these probabilities break if there’s a word that never appears in the given datasets.\n",
    "- Change `review` to `\"This cribb was amazing\"`. \n",
    "- Notice the second `b` in `cribb`.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 2**  \n",
    "- Inside your `for` loop, when you multiply `pos_probability` and `neg_probability` by a fraction, add `1` to the numerator.\n",
    "- Make sure to include parentheses around the numerator!\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 3**  \n",
    "- In the denominator of those fractions, add the number of unique words in the appropriate dataset.\n",
    "- For the positive probability, this should be the length of `pos_counter` which can be found using `len()`.\n",
    "- Again, make sure to put parentheses around your denominator so the division happens after the addition!\n",
    "- Did smoothing fix the problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75597ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0906857688451484e-12, 1.8834508880130966e-13)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = \"This cribb was amazing\"\n",
    "\n",
    "percent_pos = 0.5\n",
    "percent_neg = 0.5\n",
    "\n",
    "total_pos = sum(pos_counter.values())\n",
    "total_neg = sum(neg_counter.values())\n",
    "\n",
    "pos_probability = 1\n",
    "neg_probability = 1\n",
    "\n",
    "review_words = review.split()\n",
    "\n",
    "for word in review_words:\n",
    "    word_in_pos = pos_counter[word]\n",
    "    word_in_neg = neg_counter[word]\n",
    "    \n",
    "    pos_probability *= (word_in_pos + 1) / (total_pos + len(pos_counter))\n",
    "    neg_probability *= (word_in_neg + 1) / (total_neg + len(neg_counter))\n",
    "\n",
    "\n",
    "pos_probability, neg_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44379fbf",
   "metadata": {},
   "source": [
    "## 6. Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7289b3",
   "metadata": {},
   "source": [
    "**Task 1**  \n",
    "- After the for loop, multiply `pos_probability` by `percent_pos` and `neg_probability` by `percent_neg`.\n",
    "- Store the two values in `final_pos` and `final_neg` and print both.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 2**  \n",
    "- Compare `final_pos` to `final_neg`:\n",
    "    - If `final_pos` was greater than `final_neg`, print `\"The review is positive\"`.\n",
    "    - Otherwise print `\"The review is negative\"`.\n",
    "- Did our Naive Bayes Classifier get it right for the review `\"This crib was amazing\"`?\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 3**  \n",
    "- Replace the review `\"This crib was amazing\"` with one that you think should be classified as negative. \n",
    "- Run your program again.\n",
    "- Did your classifier correctly classify the new review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bbd9ee2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review is positive\n"
     ]
    }
   ],
   "source": [
    "review = \"You are terrible\"\n",
    "\n",
    "percent_pos = 0.5\n",
    "percent_neg = 0.5\n",
    "\n",
    "total_pos = sum(pos_counter.values())\n",
    "total_neg = sum(neg_counter.values())\n",
    "\n",
    "pos_probability = 1\n",
    "neg_probability = 1\n",
    "\n",
    "review_words = review.split()\n",
    "\n",
    "for word in review_words:\n",
    "    word_in_pos = pos_counter[word]\n",
    "    word_in_neg = neg_counter[word]\n",
    "    \n",
    "    pos_probability *= (word_in_pos + 1) / (total_pos + len(pos_counter))\n",
    "    neg_probability *= (word_in_neg + 1) / (total_neg + len(neg_counter))\n",
    "\n",
    "\n",
    "final_pos = pos_probability * percent_pos\n",
    "final_neg = neg_probability * percent_neg\n",
    "\n",
    "if final_pos > final_neg:\n",
    "    print(\"The review is positive\")\n",
    "else:\n",
    "    print(\"The review is negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0ad408",
   "metadata": {},
   "source": [
    "## 7. Formatting the Data for `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a68ac0",
   "metadata": {},
   "source": [
    "**Task 1**  \n",
    "- Create a `CountVectorizer` and name it `counter`.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 2**  \n",
    "- Call `counter`‘s `.fit()` method. `.fit()` takes a list of strings and it will learn the vocabulary of those strings.\n",
    "-  We want our counter to learn the vocabulary from both `neg_list` and `pos_list`.\n",
    "- Call `.fit()` using `neg_list + pos_list` as a parameter.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 3**  \n",
    "- Print `counter.vocabulary_`. \n",
    "- This is the vocabulary that your counter just learned. \n",
    "- The numbers associated with each word are the indices of each word when you `transform` a review.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 4**  \n",
    "- Let’s transform our brand new review. \n",
    "- Create a variable named review_counts and set it equal to counter‘s .transform`()` function. \n",
    "- Remember, `.transform()` takes a list of strings to transform. \n",
    "- So call `.transform()` using `[review]` as a parameter.\n",
    "- Print `review_counts.toarray()`. \n",
    "- If you don’t include the `toarray()`, `review_counts` won’t print in a readable format.\n",
    "- It looks like this is an array of all `0`s, but the indices that correspond to the words `\"this\"`, `\"crib\"`, `\"was\"`, and `\"amazing\"` should all be `1`.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 5**  \n",
    "- We’ll use `review_counts` as the test point for our Naive Bayes Classifier, but we also need to transform our training set.\n",
    "- Our training set is `neg_list + pos_list`. \n",
    "- Call `.transform()` using that as a parameter. \n",
    "- Store the results in a variable named `training_counts`. \n",
    "- We’ll use these variables in the next exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d603ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"This crib was amazing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b8245fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wanted': 1521, 'to': 1429, 'love': 805, 'this': 1408, 'but': 182, 'it': 712, 'was': 1525, 'pretty': 1056, 'expensive': 467, 'for': 525, 'only': 951, 'few': 495, 'months': 871, 'worth': 1584, 'of': 937, 'calendar': 187, 'pages': 981, 'ended': 434, 'up': 1486, 'buying': 185, 'regular': 1130, 'weekly': 1541, 'planner': 1024, '55': 11, 'off': 938, 'the': 1393, 'that': 1392, 'is': 709, '11': 2, 'and': 63, 'has': 618, 'all': 47, 'seven': 1219, 'days': 339, 'on': 947, 'right': 1163, 'page': 980, 'left': 765, 'room': 1166, 'write': 1588, 'do': 380, 'list': 785, 'goals': 577, 'found': 539, 'be': 120, 'more': 873, 'helpful': 633, 'because': 123, 'could': 306, 'mark': 823, 'each': 409, 'day': 337, 'eating': 417, 'sleeping': 1252, 'blocks': 149, 'then': 1397, 'also': 55, 'see': 1207, 'them': 1395, 'side': 1235, 'by': 186, 'her': 636, 'patterns': 993, 'easily': 413, 'with': 1568, 'view': 1511, 'cute': 328, 'just': 724, 'not': 919, 'what': 1550, 'like': 778, 'log': 792, 'think': 1405, 'would': 1585, 'work': 1576, 'better': 137, 'clearer': 243, 'am': 59, 'pm': 1034, 'sections': 1205, '12': 3, 'hours': 661, 'so': 1270, 'you': 1598, 'really': 1113, 'need': 903, 'two': 1474, 'if': 673, 'your': 1600, 'baby': 104, 'feeds': 490, 'or': 959, 'wets': 1549, 'lot': 803, 'in': 681, 'early': 411, 'morning': 874, 'between': 138, 'midnight': 852, '7am': 14, 'we': 1539, 're': 1104, 'cramming': 315, 'those': 1409, 'blank': 146, 'spaces': 1289, 'above': 19, 'now': 926, 'my': 888, 'wife': 1561, 'have': 623, 'six': 1243, 'month': 870, 'old': 945, 'boy': 164, 'around': 81, 'decided': 342, 'she': 1224, 'return': 1155, 'instead': 696, 'being': 132, 'stay': 1314, 'at': 92, 'home': 652, 'mom': 866, 'hired': 644, 'an': 61, 'nanny': 891, 'care': 194, 'our': 966, 'little': 787, 'arrangement': 82, 'worked': 1577, 'quite': 1097, 'well': 1544, 'ever': 452, 'since': 1240, 'shortly': 1230, 'after': 40, 'starting': 1308, 'realized': 1111, 'some': 1276, 'sort': 1285, 'journal': 723, 'track': 1446, 'activities': 28, 'while': 1556, 'he': 627, 'were': 1546, 'working': 1579, 'used': 1492, 'plain': 1022, 'notebook': 921, 'period': 1005, 'weeks': 1542, 'until': 1485, 'stumbled': 1336, 'tracker': 1447, 'daily': 332, 'childcare': 227, 'layout': 755, 'use': 1491, 'excellent': 460, 'idea': 671, 'are': 78, 'clearly': 244, 'divided': 379, 'into': 703, 'columns': 253, 'tracking': 1449, 'feedings': 489, 'nap': 892, 'time': 1425, 'diaper': 360, 'changes': 217, 'play': 1026, 'as': 86, 'general': 559, 'areas': 80, 'notes': 922, 'milestones': 855, 'legibility': 766, 'huge': 667, 'improvement': 679, 'over': 971, 'standard': 1303, 'entries': 445, 'becoming': 125, 'small': 1260, 'paragraphs': 987, 'short': 1229, 'moments': 867, 'can': 191, 'summarize': 1347, 'data': 335, 'totals': 1442, 'section': 1204, 'determine': 355, 'key': 730, 'information': 693, 'how': 665, 'much': 885, 'did': 364, 'eat': 415, 'bowel': 161, 'movement': 883, 'sleep': 1250, 'they': 1401, 'get': 564, 'etc': 449, 'there': 1399, 'however': 666, 'frustrating': 549, 'limitations': 781, 'first': 510, 'entire': 443, 'about': 18, 'half': 602, 'sheet': 1225, 'down': 392, 'middle': 851, 'portrait': 1044, 'constrains': 285, 'very': 1505, 'column': 252, 'row': 1172, 'okay': 944, 'summarized': 1348, 'ounces': 965, '34': 9, 'once': 948, 'becomes': 124, 'active': 27, 'know': 737, 'than': 1390, 'tummy': 1469, 'under': 1479, 'things': 1404, 'start': 1306, 'tight': 1423, 'another': 65, 'problem': 1067, 'covers': 313, 'out': 968, 'fine': 505, 'intention': 699, 'child': 225, 'providers': 1079, 'which': 1555, 'often': 941, 'starts': 1309, 'earlier': 410, '6am': 13, 'using': 1498, 'require': 1142, 'second': 1201, 'good': 581, 'easy': 414, 'read': 1106, 'instantly': 695, 'gather': 557, 'matter': 832, 'high': 639, 'quality': 1092, 'paper': 986, 'consistent': 282, 'don': 388, 'gets': 565, 'most': 875, 'less': 768, 'one': 949, 'babies': 103, 'cover': 312, 'thick': 1402, 'hardback': 616, 'bends': 135, 'bag': 110, 'should': 1231, 'bigger': 141, 'understand': 1480, 'portability': 1043, 'concern': 271, 'current': 326, 'size': 1244, 'entirely': 444, 'too': 1434, 'conclusion': 273, 'making': 817, 'own': 975, 'format': 533, 'spreadsheet': 1296, 'includes': 685, '24': 7, 'hour': 660, 'space': 1288, 'comments': 259, 'along': 53, 'other': 964, 'had': 601, 'bound': 160, 'cheaply': 222, 'local': 791, 'shop': 1228, 'adequate': 34, 'thought': 1411, 'keeping': 727, 'simple': 1238, 'handwritten': 608, 'nice': 913, 'haven': 624, 'thing': 1403, 'here': 637, 'why': 1560, 'when': 1551, 'breastfeeding': 171, 'phone': 1009, 'close': 245, 'keep': 726, 'yourself': 1601, 'entertained': 442, 'able': 17, 'grab': 583, 'both': 155, 'pen': 999, 'consistently': 283, 'skilled': 1247, 'me': 836, 'nurse': 928, 'same': 1179, 'place': 1019, 'every': 453, 'deprived': 351, 'least': 762, 'forget': 528, 'look': 796, 'started': 1307, 'perfect': 1002, 'app': 73, 'either': 425, 'mindlessly': 858, 'hit': 647, 'button': 183, 'connect': 276, 'gives': 571, 'example': 459, 'tell': 1385, 'long': 794, 'average': 98, 'been': 127, 'taking': 1370, 'training': 1452, 'nursed': 929, 'him': 641, '177': 5, 'times': 1427, 'last': 749, 'granted': 588, 'serves': 1215, 'no': 917, 'useful': 1493, 'purpose': 1086, 'feeling': 492, 'perverse': 1008, 'satisfaction': 1181, 'adorable': 36, 'book': 151, 'pieces': 1016, 'attached': 95, 'activity': 29, 'several': 1220, 'though': 1410, 'sew': 1221, 'make': 815, 'directed': 369, 'will': 1563, 'realize': 1110, 'priced': 1061, 'hard': 615, 'age': 42, 'group': 595, 'playing': 1027, 'teether': 1381, 'ridiculous': 1162, 'clamp': 237, 'daughter': 336, 'going': 579, 'vibrating': 1507, 'mouth': 878, 'big': 140, 'awkward': 101, 'push': 1088, 'money': 869, 'opinion': 957, 'product': 1070, 'case': 202, 'made': 812, 'bite': 144, 'vibration': 1508, 'does': 385, 'toy': 1444, 'bottom': 158, '5mo': 12, 'who': 1557, 'loves': 807, 'tap': 1373, 'toys': 1445, 'his': 645, 'yes': 1595, 'sounds': 1287, 'weird': 1543, 'husband': 668, 'drummer': 401, 'got': 582, 'obsessed': 933, 'tapping': 1376, 'even': 450, 'drinking': 397, 'bottle': 156, 'try': 1467, 'hands': 607, 'feel': 491, 'mini': 860, 'dodge': 384, 'ball': 114, 'sticks': 1320, 'face': 476, 'happy': 614, 'bought': 159, 'infant': 690, 'gum': 599, 'massager': 829, 'electric': 427, 'toothbrush': 1437, 'always': 58, 'interested': 700, 'brush': 179, 'teeth': 1380, 'supervised': 1351, 'doesn': 386, 'choke': 231, 'skinny': 1248, 'objects': 932, 'guard': 597, 'block': 148, 'prevent': 1057, 'any': 67, 'type': 1475, 'choking': 232, 'enough': 439, 'turn': 1470, 'again': 41, 'hold': 648, 'trying': 1468, 'find': 503, 'vibrations': 1509, 'himself': 642, 'sucks': 1339, 'chew': 223, 'teething': 1384, 'bites': 145, 'never': 909, 'dumb': 405, 'vibrate': 1506, 'disappointing': 372, 'liked': 779, 'massaging': 830, 'action': 26, 'took': 1435, 'finally': 502, 'battery': 119, 'gave': 558, 'nearly': 897, 'spurts': 1298, 'rest': 1149, 'wouldn': 1586, 'waste': 1531, 'great': 590, 'freaks': 541, 'wants': 1523, 'nothing': 923, 'might': 853, 'wonderful': 1574, 'appears': 75, 'hated': 621, 'cannot': 192, 'comment': 258, 'effectiveness': 421, 'bit': 143, 'seemed': 1208, 'cool': 299, 'passed': 991, 'friend': 544, 'recommended': 1118, 'throwing': 1417, 'floor': 520, 'hopefully': 656, 'squeeze': 1299, 'help': 631, 'heavy': 629, 'seems': 1209, 'enjoy': 438, 'way': 1537, 'feels': 493, 'actually': 31, 'tired': 1428, 'minute': 861, 'maybe': 835, 'older': 946, 'teethers': 1382, 'twin': 1472, 'boys': 165, 'years': 1594, 'ago': 43, 'absolutely': 21, 'loved': 806, 'new': 910, 'sought': 1286, 'surprised': 1357, 'arrived': 84, 'packaging': 978, 'stated': 1311, 'safety': 1176, 'tested': 1389, 'bpa': 166, 'lead': 757, 'phthalates': 1011, 'state': 1310, 'anywhere': 71, 'package': 977, 'free': 542, 'former': 534, 'regulator': 1131, 'medical': 841, 'devices': 359, 'sensitive': 1212, 'company': 264, 'labeling': 741, 'statements': 1312, 'perhaps': 1004, 'rather': 1102, 'err': 446, 'caution': 208, 'where': 1553, 'concerned': 272, 'lack': 742, 'clear': 242, 'pause': 994, 'specifically': 1292, 'test': 1388, 'acceptable': 22, 'amount': 60, 'allowed': 50, 'simply': 1239, 'label': 740, 'phthalate': 1010, 'eight': 424, 'sons': 1282, 'heard': 628, 'put': 1089, 'manner': 819, 'plastic': 1025, 'their': 1394, 'mouths': 879, 'sure': 1356, 'riddled': 1161, 'strongly': 1332, 'suspected': 1358, 'dangerous': 333, 'conscience': 279, 'allow': 49, 'anything': 70, 'may': 834, 'contain': 288, 'someone': 1277, 'site': 1241, 'indicated': 686, 'representative': 1141, 'from': 547, 'told': 1433, 'still': 1321, 'skeptical': 1246, 'such': 1337, 'companies': 263, 'proudly': 1077, 'products': 1071, 'language': 746, 'confused': 275, 'son': 1281, 'suck': 1338, 'fingers': 506, 'messaging': 848, 'corn': 301, 'squeezed': 1300, 'order': 960, 'young': 1599, 'already': 54, 'isn': 710, 'reason': 1114, 'pick': 1012, 'car': 193, 'stuffed': 1335, 'different': 367, 'complaint': 266, 'star': 1304, 'bead': 121, 'end': 433, 'pointy': 1038, 'catches': 205, 'sore': 1284, 'coming': 257, 'wrong': 1591, 'cry': 324, 'colors': 251, 'definitely': 345, 'catch': 204, 'eye': 473, 'overall': 972, 'ok': 943, 'price': 1060, 'necklace': 902, 'weren': 1547, 'reviewer': 1157, 'pointed': 1037, 'chews': 224, 'edge': 420, 'painful': 984, 'thrown': 1418, 'having': 626, 'pull': 1080, 'road': 1164, 'week': 1540, 'screamed': 1194, 'suddenly': 1340, 'back': 106, 'crying': 325, 'hysterically': 669, 'sling': 1255, 'seen': 1210, 'mothers': 877, 'these': 1400, 'before': 128, 'childbirth': 226, 'class': 238, 'raved': 1103, 'excited': 461, 'received': 1115, 'gift': 567, 'cradle': 314, 'position': 1045, 'afraid': 39, 'sufficate': 1341, 'fabric': 474, 'hand': 603, 'next': 912, 'easier': 412, 'grocery': 594, 'store': 1325, 'pulled': 1081, 'shoulder': 1232, 'crawling': 316, 'pulling': 1082, 'restrained': 1151, 've': 1503, 'tried': 1462, 'kangaroo': 725, 'scared': 1188, 'fall': 479, 'wiggle': 1562, 'worm': 1582, 'strap': 1328, 'neck': 901, 'interfere': 701, 'circulation': 236, 'glad': 573, 'rethink': 1153, 'kind': 733, 'carrier': 198, 'slings': 1256, 'practiced': 1050, 'cat': 203, 'comfortable': 256, 'must': 887, 'admit': 35, 'front': 548, 'packs': 979, 'cut': 327, 'across': 25, 'go': 576, 'carry': 199, 'screams': 1195, 'hardly': 617, 'cries': 320, 'say': 1187, 'mean': 838, 'turns': 1471, 'red': 1123, 'soon': 1283, 'take': 1366, 'pack': 976, 'honestly': 653, 'lay': 754, 'cooperates': 300, 'carried': 197, 'brought': 178, 'hospital': 659, 'walking': 1519, 'plan': 1023, 'hip': 643, 'watched': 1534, 'video': 1510, 'support': 1354, 'hope': 654, 'stick': 1318, 'traditional': 1451, 'larger': 748, 'women': 1572, 'endowed': 435, 'purchased': 1085, 'total': 1441, 'thinking': 1406, 'needed': 904, 'change': 215, 'bedding': 126, 'constantly': 284, 'due': 404, 'spit': 1295, 'instructions': 697, 'said': 1177, 'hang': 610, 'dry': 402, 'through': 1414, 'toss': 1440, 'dryer': 403, 'mattress': 833, 'known': 739, 'didn': 365, 'extra': 471, 'went': 1545, 'cosleeper': 304, 'material': 831, 'special': 1290, 'holds': 650, 'lots': 804, 'washes': 1527, 'uses': 1497, 'shipping': 1227, 'quick': 1095, 'sheets': 1226, 'themselves': 1396, 'soft': 1271, 'course': 311, 'inexpensive': 689, 'expected': 464, 'five': 513, 'co': 246, 'sleeper': 1251, 'assembled': 90, 'yet': 1596, 'box': 163, 'torn': 1439, 'dented': 348, 'looking': 798, 'contents': 292, 'looks': 799, 'law': 753, 'puts': 1090, 'together': 1432, 'stroller': 1331, 'won': 1573, 'fit': 511, 'graco': 585, 'straps': 1329, 'tie': 1421, 'trays': 1457, 'came': 190, 'un': 1478, 'sewed': 1222, 'buy': 184, 'happened': 612, 'unforutnately': 1481, 'travel': 1456, 'system': 1361, 'carseat': 201, 'grace': 584, 'marathon': 822, 'useless': 1495, 'quattro': 1093, 'metrolite': 850, 'complete': 268, 'primarily': 1062, 'takes': 1369, 'trash': 1455, 'bags': 111, 'supposed': 1355, 'couple': 309, 'quickly': 1096, 'discovered': 374, 'pail': 982, 'full': 550, 'dropping': 399, 'mechanism': 840, 'stuck': 1334, 'forcing': 527, 'clean': 240, 'whenever': 1552, 'wipe': 1564, 'messy': 849, 'load': 790, 'top': 1438, 'routinely': 1170, 'flip': 518, 'dump': 406, 'dirty': 370, 'lift': 774, 'whole': 1559, 'lid': 770, 'allows': 51, 'tabs': 1364, 'getting': 566, 'trap': 1454, 'smell': 1262, 'negates': 906, 'makes': 816, 'something': 1278, 'cheaper': 221, 'bad': 108, 'proof': 1074, 'fact': 477, 'empty': 432, 'leaks': 758, 'pleasant': 1029, 'truly': 1466, 'believe': 133, 'best': 136, 'market': 824, 'garbage': 555, 'fantastic': 481, 'job': 719, 'containing': 290, 'odors': 936, 'couldn': 307, 'biggest': 142, 'kitchen': 734, 'sized': 1245, 'champ': 214, 'requires': 1144, 'us': 1490, 'remove': 1138, 'wasteful': 1532, 'solution': 1275, 'smaller': 1261, 'accomodate': 23, 'common': 260, 'household': 663, 'tall': 1372, 'efficiently': 422, 'point': 1036, 'separate': 1213, 'disguise': 376, 'doubt': 391, 'expend': 466, 'effort': 423, 'works': 1580, 'piston': 1018, 'drop': 398, 'joint': 720, 'meet': 844, 'thus': 1419, 'caught': 207, 'its': 716, 'replacement': 1140, 'moved': 882, 'drum': 400, 'foot': 524, 'securing': 1206, 'handed': 604, 'operation': 956, 'states': 1313, 'third': 1407, 'trip': 1463, 'ask': 87, 'china': 230, 'contains': 291, 'category': 206, 'throw': 1416, 'soiled': 1272, 'ours': 967, 'tends': 1387, 'lazy': 756, 'fill': 499, 'yuck': 1602, 'save': 1182, 'diapers': 362, 'reading': 1107, 'reviews': 1159, 'line': 782, 'chose': 234, 'register': 1127, 'disappointed': 371, 'sense': 1211, 'super': 1350, 'hero': 638, 'smelly': 1265, 'enter': 440, 'corner': 302, 'guess': 598, 'grateful': 589, 'house': 662, 'poopie': 1040, 'wet': 1548, 'scented': 1189, 'away': 99, 'garabage': 554, 'taken': 1367, 'opening': 954, 'difficult': 368, 'blue': 150, 'round': 1168, 'part': 990, 'broke': 176, 'masking': 827, 'tape': 1374, 'thrilled': 1413, 'specific': 1291, 'cheap': 220, 'smells': 1264, 'large': 747, 'far': 482, 'gab': 553, 'nature': 895, 'awesome': 100, 'stinks': 1322, 'neat': 898, 'disposal': 377, 'shower': 1233, 'handle': 606, 'purchase': 1084, 'liners': 784, 'mistake': 864, 'stars': 1305, 'parents': 989, 'children': 228, '14': 4, 'come': 254, 'odor': 934, 'literally': 786, 'smelled': 1263, 'poop': 1039, 'stand': 1302, 'changed': 216, 'saving': 1184, 'plus': 1033, 'infants': 691, 'want': 1520, 'consider': 281, 'else': 428, 'decor': 343, 'gifts': 568, 'favorite': 483, 'positive': 1046, 'open': 952, 'without': 1570, 'breaking': 168, 'nail': 890, 'changing': 218, 'depending': 349, 'waited': 1515, 'door': 390, 'knot': 736, 'brim': 173, 'dispose': 378, 'squirmy': 1301, 'table': 1363, 'registered': 1128, 'item': 714, 'impressed': 677, 'jammed': 718, 'leaves': 764, 'faint': 478, 'live': 788, 'hassle': 620, 'beware': 139, 'value': 1501, 'manicures': 818, 'refills': 1126, 'pleased': 1031, 'diet': 366, 'bowl': 162, 'movements': 884, 'longer': 795, 'contained': 289, 'tightly': 1424, 'wrap': 1587, 'washing': 1528, 'frequently': 543, 'stench': 1317, 'comes': 255, 'maintain': 813, 'serious': 1214, 'design': 352, 'flaw': 516, 'tapered': 1375, 'noticeably': 925, 'probably': 1066, 'balancing': 113, 'purposes': 1087, 'pros': 1075, 'alternatives': 57, 'normal': 918, 'bagscons': 112, 'glowing': 575, 'receiving': 1116, 'replace': 1139, 'broken': 177, 'genie': 560, 'disappointment': 373, 'complaints': 267, 'unsanitary': 1483, 'putting': 1091, 'wipes': 1565, 'slot': 1257, 'dumping': 407, 'bucket': 180, 'germy': 563, 'mess': 847, 'unrealistic': 1482, 'fear': 484, 'toddler': 1431, 'near': 896, 'germs': 562, 'let': 769, 'frightening': 546, 'experience': 468, 'yikes': 1597, 'prevention': 1058, 'prepared': 1055, 'opened': 953, 'seals': 1198, 'individual': 688, 'sea': 1196, 'ones': 950, 'certainly': 211, 'arrives': 85, 'year': 1593, 'll': 789, 'cleaner': 241, 'involved': 707, 'version': 1504, 'operate': 955, 'model': 865, 'cross': 321, 'stays': 1316, 'friends': 545, 'houses': 664, 'fought': 538, 'genies': 561, 'warm': 1524, 'appeared': 74, 'lysol': 811, 'various': 1502, 'tricks': 1460, 'mask': 826, 'emanating': 429, 'luck': 809, 'breast': 169, 'fed': 486, 'imagine': 674, 'solids': 1274, 'ick': 670, 'wondering': 1575, 'fighting': 496, 'option': 958, 'air': 45, 'conditioning': 274, 'summer': 1349, 'reviewers': 1158, 'complained': 265, 'completely': 269, 'convenient': 298, 'drag': 395, 'extremely': 472, 'horrible': 658, 'please': 1030, 'figured': 498, 'protection': 1076, 'desired': 353, 'badly': 109, 'multiple': 886, 'nasty': 894, 'spew': 1294, 'forth': 536, 'sealed': 1197, 'somewhat': 1280, 'correctly': 303, 'concept': 270, 'fabulous': 475, 'cons': 278, 'area': 79, 'addition': 33, 'odorless': 935, 'notice': 924, 'worse': 1583, 'cost': 305, 'savings': 1185, 'began': 129, 'cylinder': 329, 'continually': 293, 'fun': 551, 'apart': 72, '00': 0, 'placed': 1020, 'hole': 651, 'sometimes': 1279, 'dealing': 341, 'flipped': 519, 'fell': 494, 'task': 1377, 'retrieve': 1154, 'figure': 497, 'fix': 514, '1st': 6, 'hauled': 622, 'pickup': 1014, 'lasted': 750, 'recommend': 1117, 'newborn': 911, 'within': 1569, 'liner': 783, 'assume': 91, 'stickies': 1319, 'anymore': 68, 'groceries': 593, 'perfectly': 1003, 'deal': 340, 'babi': 102, 'italia': 713, 'pinehurst': 1017, 'classic': 239, 'crib': 318, 'ultimate': 1476, 'backup': 107, 'wash': 1526, 'problems': 1068, 'fitting': 512, 'rails': 1099, 'forced': 526, 'attach': 94, 'snaps': 1269, 'stretch': 1330, 'flat': 515, 'today': 1430, 'marks': 825, 'paint': 985, 'ah': 44, 'improvised': 680, 'rail': 1098, 'length': 767, 'actual': 30, 'usually': 1499, 'teethes': 1383, 'based': 116, 'bargains': 115, 'expectations': 463, 'night': 914, 'unsnap': 1484, '10': 1, 'places': 1021, 'engage': 437, 'bumpers': 181, 'elastic': 426, 'slats': 1249, 'attractive': 96, 'miracle': 863, 'hoped': 655, 'trouble': 1464, 'lifting': 775, 'lightweight': 777, 'foam': 521, 'result': 1152, 'seconds': 1203, 'snapping': 1268, 'ties': 1422, 'bending': 134, 'solid': 1273, 'minutes': 862, 'manufacturer': 820, 'recommends': 1119, 'means': 839, 'snap': 1267, 'suggest': 1343, 'coil': 249, 'center': 209, 'feeding': 488, 'schedule': 1190, 'life': 771, 'doctor': 382, 'questions': 1094, 'habits': 600, 'saver': 1183, 'trends': 1459, 'answer': 66, 'pediatrician': 996, 'communicate': 261, 'everyone': 455, 'required': 1143, 'leave': 763, 'finish': 507, 'haves': 625, 'helps': 635, 'exactly': 458, 'gone': 580, 'mother': 876, 'watching': 1535, 'happier': 613, 'routine': 1169, 'sitter': 1242, 'helped': 632, 'prepare': 1054, 'evening': 451, 'likely': 780, 'sick': 1234, 'many': 821, 'producing': 1069, 'dehydrated': 346, 'note': 920, 'writes': 1589, 'whether': 1554, 'lunch': 810, 'playtime': 1028, 'included': 684, 'walk': 1517, 'moms': 868, 'wanting': 1522, 'kids': 731, 'dads': 331, 'lol': 793, 'alternative': 56, 'printing': 1064, 'searching': 1199, 'crumpled': 323, 'piece': 1015, 'previous': 1059, 'preferred': 1053, 'held': 630, 'basics': 117, 'wish': 1566, 'struggle': 1333, 'caretaker': 196, 'wrote': 1592, 'spend': 1293, 'neighbor': 907, 'loosely': 801, 'developing': 356, 'milk': 856, 'cohesion': 248, 'visits': 1514, 'brand': 167, 'books': 152, 'absolute': 20, 'trackers': 1448, 'available': 97, 'naps': 893, 'tracks': 1450, 'nights': 915, 'important': 676, 'during': 408, 'caregiver': 195, 'postpartum': 1047, 'nurses': 930, 'urination': 1489, 'remind': 1137, 'overwhelmed': 973, 'remember': 1135, 'cried': 319, 'major': 814, 'contact': 287, 'call': 188, 'trend': 1458, 'indication': 687, 'suggested': 1344, 'pumping': 1083, 'supplement': 1352, 'formula': 535, 'sufficient': 1342, 'water': 1536, 'drink': 396, 'supply': 1353, 'breastmilk': 172, 'wasn': 1530, 'giving': 572, 'gas': 556, 'ate': 93, 'food': 522, 'allergy': 48, 'peanut': 995, 'family': 480, 'smile': 1266, 'visit': 1512, 'ect': 419, 'memory': 846, 'babysitter': 105, 'grandma': 586, 'goes': 578, 'recorded': 1121, 'diary': 363, 'certain': 210, 'suit': 1345, 'rough': 1167, 'refer': 1124, 'forgot': 529, 'woke': 1571, 'emergency': 431, 'consent': 280, 'form': 531, 'needs': 905, 'immunizations': 675, 'info': 692, 'glance': 574, 'developmental': 358, 'organized': 963, 'create': 317, 'spreadsheets': 1297, 'people': 1000, 'practical': 1049, 'pees': 998, 'poops': 1041, 'breastfeed': 170, 'especially': 448, 'adults': 37, 'sharing': 1223, 'responsibilities': 1148, 'wake': 1516, 'eaten': 416, 'written': 1590, 'record': 1120, 'dr': 394, 'appts': 77, 'analyze': 62, 'asks': 89, 'urinating': 1488, 'realizing': 1112, 'oh': 942, 'hasn': 619, 'slept': 1254, 'number': 927, 'done': 389, 'looked': 797, 'pattern': 992, 'routines': 1171, 'jot': 721, 'knew': 735, 'beginning': 130, 'transfer': 1453, 'everything': 456, 'funny': 552, 'forgotten': 530, 'born': 154, 'pee': 997, 'poopy': 1042, 'asking': 88, 'per': 1001, 'bring': 174, 'color': 250, 'code': 247, 'pottied': 1048, 'ordering': 961, 'ummmm': 1477, 'pain': 983, 'killers': 732, 'mass': 828, 'hormones': 657, 'slowly': 1259, 'lst': 808, 'minds': 859, 'handy': 609, 'eats': 418, 'discuss': 375, 'progress': 1072, 'grandparents': 587, 'watch': 1533, 'doing': 387, 'highly': 640, 'continue': 294, 'delivery': 347, 'saw': 1186, 'ends': 436, 'swear': 1360, 'throughout': 1415, 'mile': 854, 'stone': 1323, '8230': 16, 'outings': 969, 'temperature': 1386, 'readings': 1108, 'calls': 189, 'stopped': 1324, 'swaddling': 1359, 'resource': 1146, 'later': 751, 'formally': 532, 'album': 46, 'valuable': 1500, 'tidbits': 1420, 'memories': 845, 'rummage': 1173, 'sale': 1178, 'helping': 634, 'ex': 457, 'visiting': 1513, 'almost': 52, 'filled': 500, 'development': 357, 'story': 1327, 'dad': 330, 'connected': 277, 'everyday': 454, 'medicine': 842, 'give': 569, 'rundown': 1175, 'three': 1412, 'issues': 711, 'necessary': 899, 'explain': 469, 'behavior': 131, 'lactation': 743, 'consultants': 286, 'contributed': 296, 'deprivation': 350, 'dark': 334, 'respond': 1147, 'referring': 1125, 'tasks': 1378, 'include': 683, 'finished': 508, 'knowing': 738, 'meal': 837, 'predicting': 1051, 'communication': 262, 'childs': 229, 'learn': 760, 'growth': 596, 'laid': 745, 'set': 1217, 'nitpick': 916, 'user': 1496, 'identical': 672, 'holding': 649, 'lean': 759, 'forward': 537, 'happend': 611, 'prior': 1065, 'remembering': 1136, 'wasi': 1529, 'kept': 729, 'moods': 872, 'became': 122, 'tool': 1436, 'documenting': 383, 'recording': 1122, 'diapering': 361, 'session': 1216, 'wayside': 1538, 'finding': 504, 'flexible': 517, 'lifestyle': 773, 'nursing': 931, 'move': 881, 'peruse': 1007, 'secondary': 1202, 'account': 24, 'talking': 1371, 'personas': 1006, 'christmas': 235, 'february': 485, 'restless': 1150, 'blending': 147, '8217': 15, 'religiously': 1132, 'stored': 1326, 'defiantly': 344, 'tricky': 1461, 'print': 1063, 'light': 776, 'grey': 592, 'bottles': 157, 'meds': 843, 'challenge': 213, 'detailed': 354, 'slots': 1258, 'prefer': 1052, 'chooses': 233, 'sleeps': 1253, 'bath': 118, 'doc': 381, 'appt': 76, 'thank': 1391, 'stayed': 1315, 'suitcase': 1346, 'loose': 800, 'output': 970, 'crucial': 322, 'iphone': 708, 'proved': 1078, 'annoying': 64, 'walked': 1518, 'scrap': 1193, 'inaccurate': 682, 'update': 1487, 'continued': 295, 'control': 297, 'add': 32, 'rely': 1133, '3mo': 10, 'chair': 212, 'jotting': 722, 'scheduling': 1192, 'twins': 1473, 'four': 540, 'givers': 570, 'inside': 694, 'feed': 487, 'intervals': 702, '30': 8, 'ribbon': 1160, 'movable': 880, 'tab': 1362, 'advertised': 38, 'keeps': 728, 'sane': 1180, 'esp': 447, 'realistic': 1109, 'filling': 501, 'download': 393, 'embrace': 430, 'world': 1581, 'entering': 441, 'tabulate': 1365, 'charts': 219, 'review': 1156, 'myself': 889, 'daycare': 338, 'workers': 1578, 'offended': 939, 'explaining': 470, 'usefulness': 1494, 'greatest': 591, 'inventions': 706, 'relying': 1134, 'learning': 761, 'overwhelming': 974, 'history': 646, 'reactions': 1105, 'coupled': 310, 'itzbeen': 717, 'pocket': 1035, 'timer': 1426, 'necessity': 900, 'lost': 802, 'mind': 857, 'takers': 1368, 'picking': 1013, 'run': 1174, 'anyone': 69, 'expecting': 465, 'items': 715, 'intake': 698, 'organize': 962, 'lifesaver': 772, 'exhausted': 462, 'sides': 1236, 'plenty': 1032, 'handing': 605, 'parent': 988, 'whoever': 1558, 'ran': 1100, 'wishing': 1567, 'researching': 1145, 'settled': 1218, 'regret': 1129, 'laugh': 752, 'progression': 1073, 'toward': 1443, 'schedules': 1191, 'count': 308, 'introduced': 705, 'foods': 523, 'offered': 940, 'signs': 1237, 'intolerance': 704, 'arrival': 83, 'seasoned': 1200, 'therapist': 1398, 'brings': 175, 'ladder': 744, 'fire': 509, 'truck': 1465, 'bored': 153, 'roll': 1165, 'nesting': 908, 'improved': 678, 'cars': 200, 'random': 1101, 'teach': 1379}\n",
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Task 1\n",
    "counter = CountVectorizer()\n",
    "\n",
    "# Task 2\n",
    "counter.fit(neg_list + pos_list)\n",
    "\n",
    "# Task 3\n",
    "print(counter.vocabulary_)\n",
    "\n",
    "# Task 4\n",
    "review_counts = counter.transform([review])\n",
    "print(review_counts.toarray())\n",
    "\n",
    "# Task 5\n",
    "training_counts = counter.transform(neg_list + pos_list)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937d6eae",
   "metadata": {},
   "source": [
    "## 8. Using scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b08bfc5",
   "metadata": {},
   "source": [
    "**Task 1**  \n",
    "- Begin by making a `MultinomialNB` object called `classifier`.\n",
    "\n",
    "```python\n",
    "classifier = MultinomialNB()\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 2**  \n",
    "- We now want to fit the classifier.\n",
    "-  We have the transformed points (found in `training_counts`), but we don’t have the labels associated with those points.\n",
    "- We made the training points by combining `neg_list` and `pos_list`. \n",
    "- So the first half of the labels should be `0` (for negative) and the second half should be `1` (for positive).\n",
    "- Create a list named `training_labels` that has 1000 `0`s followed by 1000 `1`s.\n",
    "- Note that there are 1000 negative and 1000 positive reviews. \n",
    "- Normally you could find this out by asking for the length of your dataset — in this example, we haven’t included the dataset because it takes so long to load!\n",
    "\n",
    "```python\n",
    "training_labels = [0] * 1000 + [1] * 1000\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 3**  \n",
    "- Call `classifier`‘s `.fit()` function. \n",
    "- Fit takes two parameters: \n",
    "    - the training set and \n",
    "    - the training labels.\n",
    "\n",
    "```python\n",
    "classifier.fit(training_counts, training_labels)\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 4**  \n",
    "- Call `classifier`‘s .`predict()` method and print the results. \n",
    "- This method takes a list of the points that you want to test.\n",
    "- Was your review classified as a positive or negative review?\n",
    "\n",
    "```python\n",
    "review = \"This crib was amazing\"\n",
    "review_counts = counter.transform([review])\n",
    "print(classifier.predict(review_counts))  # [1]\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 5**  \n",
    "- After printing `predict`, print a call to the `predict_proba` method. \n",
    "- The parameter to `predict_proba` should be the same as `predict`.\n",
    "- The first number printed is the probability that the review was a `0` (bad) and the second number is the probability the review was a `1` (good).\n",
    "\n",
    "```python\n",
    "print(classifier.predict_proba(review_counts))  # [[0.22699537 0.77300463]]\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "**Task 6**  \n",
    "- Change the text `review` to see the probabilities change.\n",
    "- Can you create a review that the algorithm is *really* confident about being positive?\n",
    "- The review `\"This crib was great amazing and wonderful\"` had the following probabilities: `[[ 0.04977729 0.95022271]]`\n",
    "- Can you create a review that is even *more* positive?\n",
    "- Another interesting challenge is to create a clearly negative review that our classifier thinks is positive.\n",
    "\n",
    "```python\n",
    "review = \"I like you, you are so amazing, you are so beautiful\"\n",
    "review_counts = counter.transform([review])\n",
    "print(classifier.predict_proba(review_counts))  # [[0.38680854 0.61319146]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d687d0",
   "metadata": {},
   "source": [
    "## 9. Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5182e8",
   "metadata": {},
   "source": [
    "**Task 1**\n",
    "- In the code editor, we’ve included three Naive Bayes classifiers that have been trained on different datasets. \n",
    "- The training sets used are the baby product reviews, reviews for Amazon Instant Videos, and reviews about video games.\n",
    "- Try changing review again and see how the different classifiers react!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0a3435",
   "metadata": {},
   "source": [
    "```python\n",
    "from reviews import baby_counter, baby_training, instant_video_counter, instant_video_training, video_game_counter, video_game_training\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "review = \"You are nice\"\n",
    "\n",
    "baby_review_counts = baby_counter.transform([review])\n",
    "instant_video_review_counts = instant_video_counter.transform([review])\n",
    "video_game_review_counts = video_game_counter.transform([review])\n",
    "\n",
    "baby_classifier = MultinomialNB()\n",
    "instant_video_classifier = MultinomialNB()\n",
    "video_game_classifier = MultinomialNB()\n",
    "\n",
    "baby_labels = [0] * 1000 + [1] * 1000\n",
    "instant_video_labels = [0] * 1000 + [1] * 1000\n",
    "video_game_labels = [0] * 1000 + [1] * 1000\n",
    "\n",
    "\n",
    "baby_classifier.fit(baby_training, baby_labels)\n",
    "instant_video_classifier.fit(instant_video_training, instant_video_labels)\n",
    "video_game_classifier.fit(video_game_training, video_game_labels)\n",
    "\n",
    "print(\"Baby training set: \" +str(baby_classifier.predict_proba(baby_review_counts)))\n",
    "print(\"Amazon Instant Video training set: \" + str(instant_video_classifier.predict_proba(instant_video_review_counts)))\n",
    "print(\"Video Games training set: \" + str(video_game_classifier.predict_proba(video_game_review_counts)))\n",
    "\n",
    "# Output:\n",
    "# Baby training set: [[0.39306827 0.60693173]]\n",
    "# Amazon Instant Video training set: [[0.47460014 0.52539986]]\n",
    "# Video Games training set: [[0.55099548 0.44900452]]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Codecademy-XphA9WxU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
